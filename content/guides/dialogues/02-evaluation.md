---
title: Evaluation | Dialogues @ VizChitra
description: How dialogue proposals are evaluated at VizChitra.
guide: dialogues
section: evaluation
order: 2
---

# Evaluation

A dialogue session should enable participative peer learning through thoughtful, question-led exploration.

> A genuine conversation is one where each person is prepared to be surprised.
> â€” Theodore Zeldin

**The Shared Journey** in the dialogue submission we are looking for:

- **Question:** Anchors the session in a clear, meaningful, discussion-worthy prompt.
- **Intent:** States why this conversation matters now for the data visualisation community.
- **Facilitation:** Describes how you will guide the discussion without turning it into a talk or workshop.
- **Structure:** Outlines a light conversational architecture that supports flow and inclusion.
- **Participation:** Invites active peer exchange rather than passive listening.
- **Discovery:** Aims for shared understanding and new insight, not predetermined answers.

## Dialogue Evaluation Rubric

Your submission will be reviewed by our Editorial Team and a group of experienced facilitators. We aim to have a **rough consensus** amongst the multiple evaluators for each proposal. The evaluation rubric below is how each one of them will be looking at the proposal.

| Criteria                    | Strong                                                                                              | Maybe                                                                 | Weak                                                                                |
| --------------------------- | --------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------- | ----------------------------------------------------------------------------------- |
| **Question Clarity**        | Anchored in a sharp, meaningful, and discussion-worthy question that invites multiple perspectives. | Clear question but somewhat broad or predictable.                     | Topic is vague, generic, or framed as a presentation rather than a question.        |
| **Facilitation Desig**n\*\* | Thoughtful conversational architecture with clear flow, inclusion methods, and time structure.      | Basic facilitation plan described but lacks depth or clarity in flow. | No clear facilitation strategy; risks becoming a talk or unstructured conversation. |
| **Participant Engagement**  | Actively designed for balanced peer exchange and equitable participation.                           | Some participatory elements mentioned but not fully structured.       | Primarily passive or dominated by facilitator; limited peer interaction.            |
| **Depth of Exploration**    | Designed to move beyond opinions into nuance, tension, and shared insight.                          | Likely to generate discussion but may remain surface-level.           | Likely to remain anecdotal or opinion-driven without deeper exploration.            |
| **Openness & Curiosity**    | Embraces uncertainty and collective discovery without predetermined conclusions.                    | Some openness but subtly oriented toward fixed outcomes.              | Clearly solution-driven or framed around promoting a viewpoint.                     |
| **Community Relevance**     | Clearly articulates why this dialogue matters now for the data visualisation community.             | Some relevance stated but impact not strongly justified.              | Limited clarity on why this conversation benefits the community.                    |
